{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(1)_MNIST_DCGAN_0413_week1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuJ2pqI6LuTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFLTHTGCSSCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시드값 설정\n",
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.set_random_seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnEPhVb9M8MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 생성자 모델 생성\n",
        "generator = Sequential()\n",
        "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2))) #128은 임의로 정한 노드의 수임, 7*7 이미지의 최초 크기, input_dim=100 100차원의 랜덤 벡터 준비\n",
        "generator.add(BatchNormalization()) # 배치 정규화\n",
        "generator.add((Reshape(7, 7, 128))) # 컨볼루션 레이어가 받아들일 수 있는 형태로 바꾸어주는 코드\n",
        "generator.add(UpSampling2D()) # 이미지의 가로, 세로 크기를 2배씩 늘려줌 => 14*14 크기로 늘어남\n",
        "generator.add(Conv2D(64, kernel_size=3, padding='same')) # padding='same' 모자라는 부분은 0으로 채워줌\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Activation(LeakyReLU(0.2))) # 불안정한 ReLu 말고 변형한 LeakyReLu, 0보다 작을 경우 0.2를 곱해라\n",
        "# LeakyReLU()함수는 ReLU() 함수에서 x값이 음수이면 무조건 0이 되어 뉴런들이 일찍 소실되는 단점을 보완하기 위해 0이하에서도 작은 값을 갖게 만드는 활성화 함수임\n",
        "generator.add(UpSampling2D()) # 28*28 크기로 늘어남 (작은 크기의 이미지를 점점 늘려가면서 컨볼루션 레이어를 지나치게 하는 것이 DCGAN의 특징)\n",
        "generator.add(Conv2D(64, kernel_size=5, padding='same', activation='tanh')) # 한 번 더 컨볼루션 과정을 거친 후 판별자에게 값을 넘길 준비\n",
        "\n",
        "# 판별자 부분은 컨볼루션 신경망 모델을 그대로 가져와서 사용하면 됨\n",
        "# 판별자는 진짜인지 가짜인지 판별만 해줄 뿐, 자기 자신이 학습하는 데 쓰이는 게 아니라 생성자로 넘겨 주어 생성자가 업데이트된 이미지를 만들도록 해야 함\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape(28, 28, 1), padding='same')) # strides 마스크를 몇 칸씩 이동시킬지 옵션(default=1), 가로 세로 크기가 더 줄어 새로운 특징을 뽑아주는 효과 작용(새로운 필터를 적용한 효과)\n",
        "discriminator.add(Activation(LeakyReLU(0.2)))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
        "discriminator.add(Activation(LeakyReLU(0.2)))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Flatten()) # 가로 세로 2차원을 1차원으로 변환\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "discriminator.trainable=False # 가중치를 저장하는 학습 기능 끄기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibglLecqgg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 생성자와 판별자 연결(출력 진위 여부 가리기)\n",
        "\n",
        "g_input = Input(shape(100,)) # 랜덤 100개 벡터를 keras의 Input() 함수에 집어넣어 생성자에 입력할 g_input 생성\n",
        "dis_output = discriminator(generator(g_input)) # 28*28 크기의 이미지가 그대로 판별자 모델 discriminator()의 입력값으로 들어감, 판별=0/1\n",
        "\n",
        "# gan 모델 컴파일 (생성자와 판별자 연결)\n",
        "gan = Model(g_input, dis_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3_ieoOGM8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 조기 종료 설정\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPF6T5XkOAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 실행 함수 선언\n",
        "def gain_train(epoch, batch_size, saving_interval):\n",
        "\n",
        "  # MNIST 데이터 불러오기\n",
        "  # MNIST 데이터 다시 불러와서 이용(테스트 과정 필요 없음, 이미지만 사용 - x_train만 호출)\n",
        "  (x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "  # 가로 28, 세로 28 픽셀, 흑백1, 실수 변환\n",
        "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float')\n",
        "\n",
        "  # 0-255 사이의 픽셀 값에서 127.5를 뺀후 127.5로 나눠줌 (tanh() 함수 사용 전에 -1~1 사이의 값으로 만들어줌)\n",
        "  x_train = (x_train - 127.5) / 127.5\n",
        "\n",
        "  # batch_size만큼 mnist 손글씨 이미지 랜덤으로 불러와서 판별자에 집어넣음\n",
        "  # 실제 이미지 (1 입력)\n",
        "  true = np.ones((batch_size, 1))\n",
        "  idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "  imgs = x_train[idx]\n",
        "  d_loss_real = discriminator.train_on_batch(imgs, true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOM3-N5XM8Yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습 결과 출력\n",
        "accuracy = model.predict(x_test, y_test)[1]\n",
        "loss = model.predict(x_test, ytest)[0]\n",
        "\n",
        "print('accuracy=', accuracy, ', loss=', loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFnwykZhQm7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습 결과 시각화\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# 테스트셋 오차\n",
        "y_vloss = history.history['val_loss']\n",
        "\n",
        "# 학습셋 오차\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "# 그래프 설정 - 1\n",
        "x_len = numpy.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker'.', c='red', label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker'.', c='blue', lable='Trainset_loss')\n",
        "\n",
        "# 그리드, 레이블 설정\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "# 테스트셋 정확도\n",
        "y_vacc = history.history['val_acc']\n",
        "\n",
        "# 학습셋 정확도\n",
        "y_acc = history.history['acc']\n",
        "\n",
        "# 그래프 설정 - 2\n",
        "x_len = numpy.arange(len(y_acc))\n",
        "plt.plot(x_len, y_vacc, marker'.', c='red', label='Testset_acc')\n",
        "plt.plot(x_len, y_acc, marker'.', c='blue', lable='Trainset_acc')\n",
        "\n",
        "# 그리드, 레이블 설정\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}