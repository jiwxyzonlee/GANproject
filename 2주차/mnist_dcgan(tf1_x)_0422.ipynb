{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_dcgan(tf1.x)_0422.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZWgVTO94var",
        "colab_type": "text"
      },
      "source": [
        "copied from:\\\n",
        "https://neurowhai.tistory.com/148"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdvryH9x-yFH",
        "colab_type": "text"
      },
      "source": [
        "### Q1. In[19] reuse=None 으로 해놓은 discriminator 어떻게 해결해야 하나"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbJETkLy5B3d",
        "colab_type": "code",
        "outputId": "e5889153-e937-469e-b003-bd869ed3e8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gl4oS6fR_yN",
        "colab_type": "code",
        "outputId": "ed8b7e89-2bea-48f4-9e61-e7c3dc6337e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vUKwFxs_KbF",
        "colab_type": "text"
      },
      "source": [
        "### 일단 DCGAN 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F39K4AY74ggH",
        "colab_type": "code",
        "outputId": "fe66ae15-1168-4d53-a012-db64c54c2fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "#-*- coding: utf-8 -*-\n",
        " \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        " \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        " \n",
        "total_epoch = 100\n",
        "batch_size = 100\n",
        "n_noise = 100\n",
        " \n",
        "D_global_step = tf.Variable(0, trainable=False, name='D_global_step')\n",
        "G_global_step = tf.Variable(0, trainable=False, name='G_global_step')\n",
        " \n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "# 생성할 이미지 저장 위치 지정\n",
        "save_dir = './datasets/dcgan_images/'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.mkdir(save_dir)\n",
        " \n",
        "def leaky_relu(x, leak=0.2):\n",
        "    return tf.maximum(x, x * leak)\n",
        " \n",
        "def generator(noise):\n",
        "    with tf.variable_scope('generator'):\n",
        "        output = tf.layers.dense(noise, 128*7*7)\n",
        "        output = tf.reshape(output, [-1, 7, 7, 128])\n",
        "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        output = tf.layers.conv2d_transpose(output, 64, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        output = tf.layers.conv2d_transpose(output, 32, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        output = tf.layers.conv2d_transpose(output, 1, [5, 5], strides=(1, 1), padding='SAME')\n",
        "        output = tf.tanh(output)\n",
        "    return output\n",
        " \n",
        "def discriminator(inputs, reuse=None):\n",
        "    with tf.variable_scope('discriminator') as scope:\n",
        "        if reuse:\n",
        "            scope.reuse_variables()\n",
        "        output = tf.layers.conv2d(inputs, 32, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(output)\n",
        "        output = tf.layers.conv2d(output, 64, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        output = tf.layers.conv2d(output, 128, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        flat = tf.contrib.layers.flatten(output)\n",
        "        output = tf.layers.dense(flat, 1, activation=None)\n",
        "    return output\n",
        " \n",
        "def get_noise(batch_size, n_noise):\n",
        "    return np.random.uniform(-1.0, 1.0, size=[batch_size, n_noise])\n",
        " \n",
        "def get_moving_noise(batch_size, n_noise):\n",
        "    assert batch_size > 0\n",
        " \n",
        "    noise_list = []\n",
        "    base_noise = np.random.uniform(-1.0, 1.0, size=[n_noise])\n",
        "    end_noise = np.random.uniform(-1.0, 1.0, size=[n_noise])\n",
        " \n",
        "    step = (end_noise - base_noise) / batch_size\n",
        "    noise = np.copy(base_noise)\n",
        "    for _ in range(batch_size - 1):\n",
        "        noise_list.append(noise)\n",
        "        noise = noise + step\n",
        "    noise_list.append(end_noise)\n",
        "    \n",
        "    return noise_list\n",
        " \n",
        "G = generator(Z)\n",
        "D_real = discriminator(X)\n",
        "D_gene = discriminator(G, True)\n",
        " \n",
        "loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=D_real, labels=tf.ones_like(D_real)\n",
        "))\n",
        "loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=D_gene, labels=tf.zeros_like(D_gene)\n",
        "))\n",
        " \n",
        "loss_D = loss_D_real + loss_D_gene\n",
        "loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "    logits=D_gene, labels=tf.ones_like(D_gene)\n",
        "))\n",
        " \n",
        "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "    scope='discriminator')\n",
        "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "    scope='generator')\n",
        " \n",
        "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "with tf.control_dependencies(update_ops):\n",
        "    train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
        "        var_list=vars_D, global_step=D_global_step)\n",
        "    train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
        "        var_list=vars_G, global_step=G_global_step)\n",
        " \n",
        "tf.summary.scalar('loss_D', loss_D)\n",
        "tf.summary.scalar('loss_G', loss_G)\n",
        " \n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        " \n",
        "    merged = tf.summary.merge_all()\n",
        "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
        " \n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        " \n",
        "    for epoch in range(total_epoch):\n",
        "        loss_val_D, loss_val_G = 0, 0\n",
        " \n",
        "        batch_xs, batch_ys = None, None\n",
        "        noise = None\n",
        " \n",
        "        for i in range(total_batch):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "            noise = get_noise(batch_size, n_noise)\n",
        " \n",
        "            _, loss_val_D = sess.run([train_D, loss_D],\n",
        "                feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
        "            _, loss_val_G = sess.run([train_G, loss_G],\n",
        "                feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
        " \n",
        "        summary = sess.run(merged,\n",
        "            feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
        "        writer.add_summary(summary, global_step=sess.run(G_global_step))\n",
        " \n",
        "        print('Epoch:', '%04d' % epoch,\n",
        "            'D loss: {:.4}'.format(loss_val_D),\n",
        "            'G loss: {:.4}'.format(loss_val_G))\n",
        " \n",
        "        if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "            sample_size = 10\n",
        "            noise = get_noise(sample_size, n_noise)\n",
        "            samples = sess.run(G, feed_dict={Z: noise, is_training: False})\n",
        "            test_noise = get_moving_noise(sample_size, n_noise)\n",
        "            test_samples = sess.run(G, feed_dict={Z: test_noise, is_training: False})\n",
        " \n",
        "            fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
        " \n",
        "            for i in range(sample_size):\n",
        "                ax[0][i].set_axis_off()\n",
        "                ax[1][i].set_axis_off()\n",
        "                ax[0][i].imshow(np.reshape(samples[i], (28, 28)))\n",
        "                ax[1][i].imshow(np.reshape(test_samples[i], (28, 28)))\n",
        " \n",
        "            plt.savefig('./datasets/dcgan_images/{}.png'.format(str(epoch).zfill(3)),\n",
        "                bbox_inches='tight')\n",
        "            \n",
        "            plt.show()\n",
        "            plt.close(fig)\n",
        "\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6b1262f6bc3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./datasets/dcgan_images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/dcgan_images/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO1U3YIn_RUi",
        "colab_type": "text"
      },
      "source": [
        "### DCGAN의 discriminator network만 가져와서 정상 mnist와 불량 mnist 넣고 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB6grp7y-ovF",
        "colab_type": "code",
        "outputId": "08ea9f50-eb6d-4368-b138-27fbc1576a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# tf.reset_default_graph()\n",
        "from keras.models import Model\n",
        "\n",
        "train_x = input_data.read_data_sets(\"./mnist/data/\", one_hot=True, validation_size=1000)\n",
        "test_x = input_data.read_data_sets(\"./mnist/data/\", one_hot=True, validation_size=1000)\n",
        "\n",
        "# x_train = train_x.tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "# x_test = test_x.tf.placeholer(tf.float32, [None, 28, 28, 1])\n",
        "\n",
        "train_x = np.ones((1000, 7, 7, 64))\n",
        "test_x = np.ones((1000, 7, 7, 64))\n",
        "# x_train = np.reshape(train_x, (len(train_x), 28, 28, 1))\n",
        "# x_test = np.reshape(test_x, (len(test_x), 28, 28, 1))\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "X = x_train.astype('float32') / 255.\n",
        "anomal_X = x_test_noisy.astype('float32') / 255."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r1WWDOe73o1",
        "colab_type": "code",
        "outputId": "a6f9cb6b-397b-47f7-dcb9-0f801ce699bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "# tf.reset_default_graph()\n",
        "# tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "D_X = discriminator(X)\n",
        "D_An_X = discriminator(anomal_X)\n",
        "\n",
        "\n",
        "score = Model.evaluate(D_X, A_X, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9eddeda65920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mD_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mD_An_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manomal_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1707a2ca17d0>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(inputs, reuse)\u001b[0m\n\u001b[1;32m     47\u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused, virtual_batch_size, adjustment)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m       _scope=name)\n\u001b[0;32m--> 327\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \"\"\"\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n    relative to /tensorflow-1.15.2/python3.6/tensorflow_core/python:\n\n    layers/normalization.py:167 call\n        return super(BatchNormalization, self).call(inputs, training=training)\n    keras/layers/normalization.py:659 call\n        outputs = self._fused_batch_norm(inputs, training=training)\n    keras/layers/normalization.py:517 _fused_batch_norm\n        training, _fused_batch_norm_training, _fused_batch_norm_inference)\n    keras/utils/tf_utils.py:59 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    framework/smart_cond.py:59 smart_cond\n        name=name)\n    util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    ops/control_flow_ops.py:1224 cond\n        orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n    ops/control_flow_ops.py:1061 BuildCondBranch\n        original_result = fn()\n    keras/layers/normalization.py:503 _fused_batch_norm_training\n        data_format=self._data_format)\n    ops/nn_impl.py:1501 fused_batch_norm\n        name=name)\n    ops/gen_nn_ops.py:4620 fused_batch_norm_v3\n        name=name)\n    framework/op_def_library.py:367 _apply_op_helper\n        g = ops._get_graph_from_inputs(_Flatten(keywords.values()))\n    framework/ops.py:5979 _get_graph_from_inputs\n        _assert_same_graph(original_graph_element, graph_element)\n    framework/ops.py:5914 _assert_same_graph\n        (item, original_item))\n\n    ValueError: Tensor(\"cond_7/Const:0\", shape=(0,), dtype=float32) must be from the same graph as Tensor(\"discriminator_8/conv2d_1/BiasAdd:0\", shape=(1000, 7, 7, 64), dtype=float32).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrkcpHod4eMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator(inputs, reuse=None):\n",
        "    with tf.variable_scope('discriminator') as scope:\n",
        "        if reuse:\n",
        "            scope.reuse_variables()\n",
        "        output = tf.layers.conv2d(inputs, 32, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(output)\n",
        "        output = tf.layers.conv2d(output, 64, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        output = tf.layers.conv2d(output, 128, [5, 5], strides=(2, 2), padding='SAME')\n",
        "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
        "        flat = tf.contrib.layers.flatten(output)\n",
        "        output = tf.layers.dense(flat, 1, activation=None)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll9IzUtC-s4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_real.predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ahLzTjAOWD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2geEJvOdOWGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCIcb-wXOWIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwUiGPvZOWKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}